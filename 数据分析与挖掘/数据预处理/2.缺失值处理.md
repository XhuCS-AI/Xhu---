### 为什么填补缺失值？

缺失值处理是数据预处理中的一步。一句话，数据预处理的目的都是使得数据能被模型更好的接受。

### 缺失值来源：

1. 收集的时候收集漏了。
2. 合并表格时，某些表格没有这列数据，就会导致缺失。

### 缺失值类型：

缺失值按出现的地方分为两种：featrues(特征) 里面出现和 target(目标) 里面出现。其中 features 里面出现是最常见的情况（特别对于工业或比赛数据集，是一定有缺失值的），而 target 里面出现则一般会考虑为半监督学习，使用半监督学习的模型来进行预测。

### 缺失值判断与处理：

缺失值的定义是，我们无法溯源情况得到的结果，就称为缺失值。最直接的判断非常简单，单元格为空或者 nun，就是缺失值。

> 要注意，根据定义除了大部分数据直接使用 nan 值来表示缺失，还要根据业务逻辑来。比如用 0 表示缺失的情况也会存在，如某些医学数据集中用 0 表示缺失

对于处理，我们会按照如下经验进行处理：

1. **缺失值占比只有 5%~8% 以下**：
   此时我们认为缺失值占比是比较小，在这种情况下，无论用什么缺失值的填补方式，对最终结果的影响不会太大。所以一般会选择均值或者其他统计量进行填充（在下方填补方法中有说明），亦或者与缺失值较多的一起使用其他方法处理都没问题。
2. **缺失值占比达到 10%~30% 左右**：
   当缺失值达到这个范围的时候，如何填补缺失值就比较考验手法了，因为对缺失值采取不同的填充方式在此时会影响到后面的最终结果，如何操作，需要具体环境具体分析。
3. **当缺失值占比比较大的时候（这没标准）**：
   如果是 70%~80% 以上可以考虑直接删了，因为数据缺太多这个特征已经没得意义了。
   如果是 40%~50% 左右的，可能还有操作空间。

下面给出一个常用的函数，可以帮我们快速的获取缺失值占比信息。

```py
def missing(df):
	missing_number = df.isnull().sum().sort_values(ascending=False)
	missing_percent = (df.isnull().sum()/len(df)*100).sort_values(ascending=False)
	missing_values = pd.concat([missing_number, missing_percent], axis=1)
	return missing_values
```

> Tips：除去上面的全部删除以外，还可以先不删，先全部填充完看看效果。然后进行特征消融或相关性检验，来判断特征对目标的预测是否有价值。

### 缺失值填补方式

1.  **统计量填补法**：使用均值，众数等。适用于对个体精度要求不大的数据。比如人口的数量年龄，经济产业情况等统计数据。

    ```py
     # 使用均值填充--对于连续型特征(人的身高，年龄等)用的最多
     df['A'].fillna(df['A'].mean(),inplace=True)

     # 使用众数填充--对于离散型特征(人的性别，文化程度)用的最多
     df['A'].fillna(df['A'].mode()[0],inplace=True)

     # 使用中位数填充--如果你不希望改变数据分布，这个好
     df['A'].fillna(df['A'].median(),inplace=True)
    ```

    当然，在为了更加合理的时候，我们会进行分组填补。比如某个样本的 B 特征是“喜欢花”，A 特征为缺失值。那么，我们就用整个数据中 B 特征为“喜欢花”的样本的均值（或者众数或者其他值）去填充他缺失的 A 特征。

    ```py
    # 举个例子：按照特征 A 分组，并用分组的均值填充 B 特征的缺失值
    df['B'] = df.groupby('A')['B'].transform(lambda x:x.fillna(x.mean()))
    ```

2.  **样本均值插值法（KNN 大法）**：
    使用 KNN 来填补缺失值，KNN 会计算缺失值附近数据点的加权均值。能够利用附近样本的相关信息来填补缺失值，适用于高维数据。缺点是是计算量大。

    ```py
    from sklearn.impute import KNNImputer

    imputer = KNNImputer(n_neighbors=3)
    df_imputed = imputer.fit_transform(df)
    ```

3.  **多重插补法（贝叶斯大法）**：
    多重插补是一种基于贝叶斯方法的插值计算。通过多次插补来估算缺失值，并最终计算一个综合的插补结果。在处理数据时，考虑到了不确定性（也就是我们填补时潜在的误差和变化范围，因为我们不可能完全填出和实际情况一样的值）。这使得其更加稳健，也更加适合需要考虑不确定性的场合（类似数据集中某个特征的值对结果非常关键，比如临床指标中的血压，或者本身业务场景就充满不确定性，比如股市与气候）。但是代价是计算复杂度高。

    ````py
    from sklearn.impute import IterativeImputer

        imputer = IterativeImputer(max_iter=10, random_state=0)
        df_imputed = imputer.fit_transform(df)
        ```

    ````

4.  **前向填充与后向填充法**：
    前向填充是指用前一个非缺失值填充缺失值，后向填充是指用后一个非缺失值填充缺失值。简单直观，多用于时序数据，但是当数据变化比较大的时候，效果并不好。

    ```py

    # 前向填充

    df['A'] = df['A'].fillna(method='ffill')

    # 后向填充

    df['A'] = df['A'].fillna(method='bfill')
    ```

5.  **其他方法**：
    其他方法如：线性插值（Linear Interpolation），多项式插值（Polynomial Interpolation）和回归插值法（Regression Imputation）等等由于假设限制或易过拟合的出现导致不好用，比如线性插值要求数据变化是线性的，多项式与回归易过拟合。因此这里不提，大家知道即可。同时，针对不同情况，有时可以将不同方法组合在一起处理，依次达到更好的效果。

### 查看缺失值填补后的数据分布：

可以使用下列代码查看填补后的数据分布状态，其中 `datas` 数组存放的是使用不同方式填补后的数据，`mths`则是对应的填充方法名称：

```py
datas = [data, data_fill_mean,data_fill_mode,data_fill_median]
mths  = ['orgin','fill_mean','fill_mode','fill_median']
plt.figure()
ax = sns.kdeplot(df, color = 'm', fill=True)
for dat in datas:
    ax = sns.kdeplot(dat)
ax = ax.legend(mths)
plt.show()
```

为什么要查看呢？这是为了保持插补后数据的统计特性和分布形态。对于某些模型而言，插补的目的是填补缺失值，同时尽量不改变原数据的特征。如果插补后的数据分布与原数据分布相似，说明插补过程有效，没有引入偏差或噪声。相反，如果分布发生明显改变，可能表示插补方法引入了不必要的误差或失真，影响了数据的真实性。
